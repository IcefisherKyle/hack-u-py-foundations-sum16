{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "### Why Test?\n",
    "* Know if your code works\n",
    "* Save time\n",
    "* Better code\n",
    "* Remove Fear\n",
    "* Debugging is hard, Testing is easy\n",
    "\n",
    "Some people look at testing like it's just a checkbox to take care of, and that's not the best way to look at it. It's a serious solution to a serious problem.\n",
    "\n",
    "### You know you should do it\n",
    "![](../../images/bad.jpg)\n",
    "\n",
    "We recognize that the the world is chaotic, and things can go wrong. Tests allow us to control the chaos.\n",
    "\n",
    "Topics\n",
    "* Growing tests\n",
    "* unittest Module\n",
    "* Mocks\n",
    "\n",
    "## Growing Tests\n",
    "Let's start with an example class of a stock portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Portfolio(object):\n",
    "    \"\"\"A simple stock portfolio\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"stocks is a list of lists:\n",
    "        [[name,shares,price,], ...]\"\"\"\n",
    "        self.stocks = []\n",
    "        \n",
    "    def buy(self, name, shares, price):\n",
    "        \"\"\"Buy 'name': 'shares' shares at 'price'.\"\"\"\n",
    "        self.stocks.append([name, shares, price])\n",
    "    \n",
    "    def cost(self):\n",
    "        \"\"\"What was the total cost of this portfolio?\"\"\"\n",
    "        amt = 0.0\n",
    "        for name,shares, price in self.stocks:\n",
    "            amt += shares* price\n",
    "        return amt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Test\n",
    "Open a python interpreter and test the code yourself. Some folks don't even get this far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Portfolio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.buy('IBM', 100, 176.48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17648.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.buy(\"HPQ\", 100, 36.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21263.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good thing is:\n",
    "* We're testing the code\n",
    "\n",
    "The bad thing is...\n",
    "* It's not repeatable\n",
    "* It's labor intensive\n",
    "* do we know if it's right?\n",
    "\n",
    "### Second Test\n",
    "Write a new python file that does all of the testing for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty portfolio cost: 0.0\n",
      "With 100 IBM @ 176.48: 17648.0\n",
      "With 100 HPQ @ 36.15: 21263.0\n"
     ]
    }
   ],
   "source": [
    "import porttest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good thing is:\n",
    "* We're testing the code\n",
    "* It's not repeatable\n",
    "* It's labor intensive\n",
    "\n",
    "The bad thing is...\n",
    "* do we know if it's right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty portfolio cost: 0.0, should be 0.0\n",
      "With 100 IBM @ 176.48: 17648.0, should be 17648.0\n",
      "With 100 HPQ @ 36.15: 21263.0, should be 21263.0\n"
     ]
    }
   ],
   "source": [
    "import porttest2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better!\n",
    "... but we still have a human look at the result.\n",
    "\n",
    "## Assert\n",
    "\n",
    "We use assert when we want to check if something is True or not. If the expression equates to True, then the python script keeps going, but if it equates to False then an exception is raised.\n",
    "\n",
    "So you could also think of it as checking if a statement is false.\n",
    "\n",
    "Often used in a function that takes specific types as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "451\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Colder than absolute zero!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-01da11082122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKelvinToFahrenheit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m273\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKelvinToFahrenheit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m505.78\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKelvinToFahrenheit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-01da11082122>\u001b[0m in \u001b[0;36mKelvinToFahrenheit\u001b[0;34m(Temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKelvinToFahrenheit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTemperature\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Colder than absolute zero!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTemperature\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m273\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKelvinToFahrenheit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m273\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Colder than absolute zero!"
     ]
    }
   ],
   "source": [
    "def KelvinToFahrenheit(Temperature):\n",
    "   assert (Temperature >= 0),\"Colder than absolute zero!\"\n",
    "   return ((Temperature-273)*1.8)+32\n",
    "\n",
    "print (KelvinToFahrenheit(273))\n",
    "print (int(KelvinToFahrenheit(505.78)))\n",
    "print (KelvinToFahrenheit(-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in our tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty portfolio cost: 0.0, should be 0.0\n",
      "With 100 IBM @ 176.48: 17648.0, should be 17648.0\n",
      "With 100 HPQ @ 36.15: 21263.0, should be 21263.0\n"
     ]
    }
   ],
   "source": [
    "import porttest3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good! Results are now checked automatically!\n",
    "\n",
    "What happens when the test fails? \n",
    "\n",
    "For this example change Portfoio.cost() to start with 0.1 instead of 0.0\n",
    "\n",
    "You'll see that the script just ends, which is not good for testing because we didn't get to our other tests. What happens if we fail test #2, but we have 10,000 more to check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import porttest3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't do anything, because there's no error to throw! The code just stops working.\n",
    "\n",
    "So things are starting to get complicated. Usually, as coders if we are coming across complicated things that lots of people encounter (like testing), we would usually look for a library. **Unittest!**\n",
    "\n",
    "#### But first, what are we looking for in our tests?\n",
    "* Automated - easier for you to run -> you will actually use them\n",
    "* Fast - easier to run\n",
    "* Reliable - if they're not, you don't gain anything from testing. No confidence, which is what tests are for. Don't ask, \"Do my tests work?\"\n",
    "* Informative - Let's you know exactly what goes wrong. \n",
    "* Focused - should exercise as little code as possible. The less code it runs, the more specific your test can be.\n",
    "\n",
    "## unittest\n",
    "* unittest = an automated test\n",
    "* Python standard library\n",
    "* Infrustraucture for well-structured tests\n",
    "\n",
    "Here's an example of a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from portfolio import Portfolio\n",
    "\n",
    "class PortfolioTest(unittest.TestCase):\n",
    "    def test_buy_one_stock(self):\n",
    "        p = Portfolio()\n",
    "        p.buy('IBM',100, 176.48)\n",
    "        assert p.cost() == 17648.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All test classes are derived from unittest.TestCase\n",
    "* test themselves, are methods that start with the word \"test\"\n",
    "\n",
    "The command that you run in python. You run \n",
    "\n",
    "```python -m unittest test.py```\n",
    "\n",
    "You get a number of dots for the number tests it ran, and counts up the number of failed test.\n",
    "\n",
    "Let's add some more tests. Take a look at the test2.py file. We now test if a portfolio is empty, and if we add two stocks. No we run our tests.\n",
    "\n",
    "```python -m unittest test2```\n",
    "\n",
    "3 dots! Which tells us that three tests passed! \n",
    "\n",
    "### Test Isolation\n",
    "* Every test gets a new test object\n",
    "* Tests can't affect each other\n",
    "    * If they did, how do you know that each test does what it's supposed to?\n",
    "    * You should be able to run a single test by itself.\n",
    "* Failure doesn't stop next tests\n",
    "\n",
    "### What happens if a test fails?\n",
    "```python -m unittest test3```\n",
    "\n",
    "### unittest assert methods\n",
    "Unittest has methods built in to make these checks for you, and gives you the information you need when it's incorrect. Check them out [here](https://docs.python.org/3/library/unittest.html).\n",
    "\n",
    "```python -m unittest test4```\n",
    "\n",
    "#### Protip! You can even write your own assert methods!\n",
    "You can engineer your tests to be structured efficiently, and refactor to make code simpler. If you do something many times, considert writing a function or method!\n",
    "\n",
    "```python -m unittest test5```\n",
    "\n",
    "### What happens if the test doesn't Pass or Fail? \n",
    "Sometimes, if there is something wrong with the test, you'll get an E rather than a . or an F. That means that your test threw an error, not your assertion.\n",
    "\n",
    "```python -m unittest test6```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
